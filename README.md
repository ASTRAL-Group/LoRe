<p align="center">
<h1 align="center"><strong>When Reasoning Meets Its Laws</strong></h1>
  <p align="center">
    <a href='https://jyzhang1208.github.io/' target='_blank'>Junyu Zhang </a><sup><img src="assets/uiuc.svg" align="center" width=0.8% >‚àó</sup>&emsp;
    <a href='https://runpeidong.web.illinois.edu/' target='_blank'>Yifan Sun </a><sup><img src="assets/uiuc.svg" align="center" width=0.8% >‚àó</sup>&emsp;
    <a href='https://rookiehb.github.io/' target='_blank'>Tianang Leng </a><sup><img src="assets/upenn.png" align="center" width=0.9% >‚àó</sup>&emsp;
    <a href='https://scholar.google.com/citations?user=-tpUy14AAAAJ&hl=en' target='_blank'>Jingyan Shen </a><sup><img src="assets/nyu.png" align="center" width=1.0% >‚àó</sup>&emsp;
    <br>
    <a href='https://geng-haoran.github.io/' target='_blank'>Liu Ziyin </a><sup><img src="assets/mit.png" align="center" width=1.1% style="margin-right:0.1em;"><img src="assets/ntt.png" align="center" width=1.3% >&#8224</sup>&emsp;
    <a href='https://xialin-he.github.io/' target='_blank'>Paul Pu Liang </a><sup><img src="assets/mit.png" align="center" width=1.1%>&#8224</sup>&emsp;
    <a href='https://www.huan-zhang.com/' target='_blank'>Huan Zhang </a><sup><img src="assets/uiuc.svg" align="center" width=0.8% >&#8224</sup>&emsp;
    <br>
    <sup><img src="assets/uiuc.svg" align="center" width=0.8% ></sup> University of Illinois Urbana-Champaign <sup>
    &emsp;&emsp;<img src="assets/mit.png" align="center" width=1.1%></sup> Massachusetts Institute of Technology
    <br>
    <sup>&emsp;&emsp;<img src="assets/upenn.png" align="center" width=0.9% ></sup> University of Pennsylvania
    <sup>&emsp;&emsp;<img src="assets/nyu.png" align="center" width=1.0% ></sup> New York University
    <sup>&emsp;&emsp;<img src="assets/ntt.png" align="center" width=1.3% ></sup> NTT Research
    <br>
    <sup>‚àó</sup> Equal contribution&emsp;<sup>&#8224;</sup> Equal mentorship
    <br>
  </p>
</p>

</p>
<p align="center">
  <a href='https://github.com/ASTRAL-Group/LoRe'>
    <img src='https://img.shields.io/badge/Arxiv-2505.24863-A42C25?style=flat&logo=arXiv&logoColor=A42C25'></a>
  <a href='https://github.com/ASTRAL-Group/LoRe'>
    <img src='https://img.shields.io/badge/Paper-PDF-yellow?style=flat&logo=arXiv&logoColor=yellow'></a>
  <a href='https://lore-project.github.io/'>
    <img src='https://img.shields.io/badge/Project-Page-green?style=flat&logo=Google%20chrome&logoColor=green'></a>
  <a href='https://github.com/ASTRAL-Group/LoRe'>
    <img src='https://img.shields.io/badge/GitHub-Code-black?style=flat&logo=github&logoColor=white'></a>
</p>

## üè† About
<div style="text-align: center;">
    <img src="assets/teaser.png" width=100% >
</div>

Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities.
<div style="text-align: center;">
    <img src="assets/framework.png" width=100% >
</div>

We present the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. LoRe introduces the *compute law* with the supplementary *accuracy law*, examined through two properties: *monotonicity* and *compositionality*. LoRe-Bench, our proposed benchmark, systematically measures these two tractable properties for LRMs. To address the compositionality gap observed in existing models, we develop an effective finetuning approach that enforces compute-law compositionality.

As a comprehensive study from theoretical hypotheses to empirical validation, we advance a theoretical perspective grounded in human reasoning for improving reasoning in LRMs. We hope LoRe can inspire more potential strategies that guide models toward their optimal paradigms of thinking.

üöß **Code release under construction ‚Äî stay tuned!** üöß

## Contact
If you have any questions related to the code or the paper, feel free to email Junyu Zhang (`junyuz6@illinois.edu`).

